{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ec39a38-98b3-4878-a20c-c9297442ca02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ildefonso/Documents/ExtraDrive/repos/vocalpy/Nicholson-Cohen-2024-bio-sound-seg-bench-0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ildefonso/Documents/ExtraDrive/repos/vocalpy/Nicholson-Cohen-2024-bio-sound-seg-bench-0.1/.venv/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd /home/ildefonso/Documents/ExtraDrive/repos/vocalpy/Nicholson-Cohen-2024-bio-sound-seg-bench-0.1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1e6e00-c913-4c5d-a06a-b1ee6db62851",
   "metadata": {},
   "source": [
    "# tweetynet-canary dataset prep\n",
    "\n",
    "This script documents how the dataset was prepared from the canary dataset accompanying the TweetyNet paper.\n",
    "\n",
    "It assumes that the dataset has been downloaded into a directory, below called `DATA_DIR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f19d1201-256f-4eaf-b586-a9af01d4b517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "import crowsetta\n",
    "import numpy as np\n",
    "import vocalpy as voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47dfc3b8-96e6-4469-a730-bed0f95ed480",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = pathlib.Path(\n",
    "    './data/raw/Canary-Song/tweetynet-canary/'\n",
    ")\n",
    "\n",
    "BIRD_IDS = [\n",
    "    'llb11',\n",
    "    'llb16',\n",
    "    'llb3',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "031f8282-4aaf-4d2d-a96f-2d0af2fe967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRY_RUN = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e327a27-0c2c-4e2f-a116-915f7bd55a2e",
   "metadata": {},
   "source": [
    "## Make sure there are no onsets less than zero\n",
    "\n",
    "We also need to make sure there are no onsets less than zero. This is a quirk of the Matlab GUI annotator, that it sometimes sets the first onset to be less than zero, so we fix it in the annotations.\n",
    "\n",
    "We check whether the first onset is less than zero, and also whether any other onsets / offsets are less than zero--there should only be cases where the first onset is less than zero, but we check anyways to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "482acb7b-3bbd-47d9-9c95-a417a490cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIBE = crowsetta.Transcriber(format='simple-seq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35a85b70-9e1e-49db-9b42-c1cd00054e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has first onset less than 0: llb16_0275_2018_05_05_13_27_07.wav.csv\n",
      "File has first onset less than 0: llb3_0071_2018_04_23_17_38_30.wav.csv\n",
      "File has first onset less than 0: llb3_0533_2018_04_25_08_43_56.wav.csv\n",
      "File has first onset less than 0: llb3_0613_2018_04_25_13_55_33.wav.csv\n",
      "File has first onset less than 0: llb3_0770_2018_04_25_17_06_20.wav.csv\n",
      "File has first onset less than 0: llb3_1055_2018_04_26_10_21_58.wav.csv\n",
      "File has first onset less than 0: llb3_1112_2018_04_26_11_39_52.wav.csv\n",
      "File has first onset less than 0: llb3_1475_2018_04_27_06_04_48.wav.csv\n",
      "File has first onset less than 0: llb3_1707_2018_04_27_13_04_15.wav.csv\n",
      "File has first onset less than 0: llb3_1826_2018_04_27_15_26_59.wav.csv\n",
      "File has first onset less than 0: llb3_2172_2018_04_28_11_27_38.wav.csv\n",
      "File has first onset less than 0: llb3_2294_2018_04_28_13_44_19.wav.csv\n",
      "File has first onset less than 0: llb3_2530_2018_04_29_05_45_17.wav.csv\n",
      "File has first onset less than 0: llb3_2538_2018_04_29_05_53_05.wav.csv\n",
      "File has first onset less than 0: llb3_2748_2018_04_29_12_12_29.wav.csv\n",
      "File has first onset less than 0: llb3_2774_2018_04_29_12_46_56.wav.csv\n",
      "File has first onset less than 0: llb3_2810_2018_04_29_13_32_52.wav.csv\n",
      "File has first onset less than 0: llb3_2969_2018_04_29_17_43_25.wav.csv\n",
      "File has first onset less than 0: llb3_2995_2018_04_29_18_18_59.wav.csv\n",
      "File has first onset less than 0: llb3_3038_2018_04_30_07_31_22.wav.csv\n",
      "File has first onset less than 0: llb3_3043_2018_04_30_07_50_38.wav.csv\n",
      "File has first onset less than 0: llb3_3281_2018_05_01_07_11_10.wav.csv\n",
      "File has first onset less than 0: llb3_3313_2018_05_01_08_22_45.wav.csv\n",
      "File has first onset less than 0: llb3_3578_2018_05_01_15_26_13.wav.csv\n",
      "File has first onset less than 0: llb3_3981_2018_05_02_14_19_55.wav.csv\n"
     ]
    }
   ],
   "source": [
    "first_onset_lt_zero = defaultdict(list)\n",
    "any_onset_lt_zero = defaultdict(list)\n",
    "any_offset_lt_zero = defaultdict(list)\n",
    "\n",
    "for bird_id in BIRD_IDS:\n",
    "    files_root = DATASET_ROOT / f\"{bird_id}_data/{bird_id}_songs\"\n",
    "    wav_paths = voc.paths.from_dir(files_root, '.wav')\n",
    "    csv_paths = voc.paths.from_dir(files_root, '.wav.csv')\n",
    "    assert len(wav_paths) == len(csv_paths), \"len(wav_paths) != len(csv_paths)\"\n",
    "    for wav_path, csv_path in zip(wav_paths, csv_paths):\n",
    "        simpleseq = SCRIBE.from_file(csv_path)\n",
    "        if simpleseq.onsets_s[0] < 0.:\n",
    "            print(\n",
    "                f\"File has first onset less than 0: {csv_path.name}\"\n",
    "            )\n",
    "            first_onset_lt_zero[bird_id].append(\n",
    "                (wav_path, csv_path)\n",
    "            )\n",
    "        elif np.any(simpleseq.onsets_s[1:]) < 0.:\n",
    "            print(\n",
    "                f\"File has onset (other than first) less than 0: {csv_path.name}\"\n",
    "            )\n",
    "            any_onset_lt_zero[bird_id].append((wav_path, csv_path))\n",
    "        elif np.any(simpleseq.offsets_s) < 0.:\n",
    "            print(\n",
    "                f\"File has offset less than 0: {csv_path.name}\"\n",
    "            )\n",
    "            any_offset_lt_zero[bird_id].append((wav_path, csv_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3c92acc-7b99-4e6f-bb7f-885d26bb6ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if any(\n",
    "    len(list_) > 0 for list_ in any_onset_lt_zero.values()\n",
    "):\n",
    "    raise ValueError()\n",
    "elif any(\n",
    "    len(list_) > 0 for list_ in any_offset_lt_zero.values()\n",
    "):\n",
    "    raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "679b3c42-fe93-4985-9ca7-8f75cfbe2b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number that will be removed from dataset for bird ID llb16: 1 / 1452 = 0.07%\n",
      "moving wav and csv path for: llb16_0275_2018_05_05_13_27_07\n",
      "Number that will be removed from dataset for bird ID llb3: 24 / 2655 = 0.90%\n",
      "moving wav and csv path for: llb3_0071_2018_04_23_17_38_30\n",
      "moving wav and csv path for: llb3_0533_2018_04_25_08_43_56\n",
      "moving wav and csv path for: llb3_0613_2018_04_25_13_55_33\n",
      "moving wav and csv path for: llb3_0770_2018_04_25_17_06_20\n",
      "moving wav and csv path for: llb3_1055_2018_04_26_10_21_58\n",
      "moving wav and csv path for: llb3_1112_2018_04_26_11_39_52\n",
      "moving wav and csv path for: llb3_1475_2018_04_27_06_04_48\n",
      "moving wav and csv path for: llb3_1707_2018_04_27_13_04_15\n",
      "moving wav and csv path for: llb3_1826_2018_04_27_15_26_59\n",
      "moving wav and csv path for: llb3_2172_2018_04_28_11_27_38\n",
      "moving wav and csv path for: llb3_2294_2018_04_28_13_44_19\n",
      "moving wav and csv path for: llb3_2530_2018_04_29_05_45_17\n",
      "moving wav and csv path for: llb3_2538_2018_04_29_05_53_05\n",
      "moving wav and csv path for: llb3_2748_2018_04_29_12_12_29\n",
      "moving wav and csv path for: llb3_2774_2018_04_29_12_46_56\n",
      "moving wav and csv path for: llb3_2810_2018_04_29_13_32_52\n",
      "moving wav and csv path for: llb3_2969_2018_04_29_17_43_25\n",
      "moving wav and csv path for: llb3_2995_2018_04_29_18_18_59\n",
      "moving wav and csv path for: llb3_3038_2018_04_30_07_31_22\n",
      "moving wav and csv path for: llb3_3043_2018_04_30_07_50_38\n",
      "moving wav and csv path for: llb3_3281_2018_05_01_07_11_10\n",
      "moving wav and csv path for: llb3_3313_2018_05_01_08_22_45\n",
      "moving wav and csv path for: llb3_3578_2018_05_01_15_26_13\n",
      "moving wav and csv path for: llb3_3981_2018_05_02_14_19_55\n"
     ]
    }
   ],
   "source": [
    "for bird_id, first_offset_lt_zero_list in first_onset_lt_zero.items():\n",
    "    if len(first_offset_lt_zero_list) < 1:\n",
    "        print(f\"No files with first offset less than zero for bird ID: {bird_id}\")\n",
    "        continue\n",
    "\n",
    "    files_root = DATASET_ROOT / f\"{bird_id}_data/{bird_id}_songs\"\n",
    "    all_wav_paths = voc.paths.from_dir(files_root, '.wav')\n",
    "    n_that_need_removing = len(first_offset_lt_zero_list)\n",
    "    print(\n",
    "        f\"Number that will be removed from dataset for bird ID {bird_id}: {n_that_need_removing} / {len(all_wav_paths)} = \"\n",
    "        f\"{n_that_need_removing / len(all_wav_paths) * 100:.2f}%\"\n",
    "    )\n",
    "\n",
    "    first_offset_lt_zero_dir = files_root / \"first_offset_lt_zero\"\n",
    "    if not DRY_RUN:\n",
    "        first_offset_lt_zero_dir.mkdir(exist_ok=True)\n",
    "    for wav_path, csv_path in first_offset_lt_zero_list:\n",
    "        print(f\"moving wav and csv path for: {wav_path.stem}\")\n",
    "        if not DRY_RUN:\n",
    "            shutil.move(wav_path, first_offset_lt_zero_dir)\n",
    "            shutil.move(csv_path, first_offset_lt_zero_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94964128-33ed-49cc-a448-112d8ba1e2e4",
   "metadata": {},
   "source": [
    "## Remove any remaining annotation files where all onset/offset times are not strictly increasing\n",
    "\n",
    "There are a few cases where onset or offset times are not strictly increasing -- the segments overlap with each other slightly.\n",
    "Rather than fix this by hand we just remove these few files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8932fdb4-4983-4aa5-82c0-e06e97b9519c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caused error when concatenating starts and stops: llb11_01876_2018_05_08_11_55_42.wav.csv\n",
      "caused error when concatenating starts and stops: llb11_02147_2018_05_08_16_01_55.wav.csv\n",
      "caused error when concatenating starts and stops: llb11_02473_2018_05_09_09_57_01.wav.csv\n",
      "caused error when concatenating starts and stops: llb11_03556_2018_05_11_10_08_16.wav.csv\n",
      "caused error when concatenating starts and stops: llb3_0357_2018_04_24_17_09_44.wav.csv\n",
      "caused error when concatenating starts and stops: llb3_0668_2018_04_25_14_50_17.wav.csv\n",
      "caused error when concatenating starts and stops: llb3_0800_2018_04_25_17_49_23.wav.csv\n",
      "caused error when concatenating starts and stops: llb3_0804_2018_04_25_17_50_45.wav.csv\n",
      "caused error when concatenating starts and stops: llb3_0824_2018_04_25_18_20_08.wav.csv\n",
      "caused error when concatenating starts and stops: llb3_1122_2018_04_26_11_49_21.wav.csv\n",
      "caused error when concatenating starts and stops: llb3_1124_2018_04_26_11_50_05.wav.csv\n",
      "caused error when concatenating starts and stops: llb3_1170_2018_04_26_12_25_11.wav.csv\n",
      "caused error when concatenating starts and stops: llb3_1412_2018_04_26_17_51_20.wav.csv\n",
      "caused error when concatenating starts and stops: llb3_1559_2018_04_27_08_04_31.wav.csv\n",
      "caused error when concatenating starts and stops: llb3_1673_2018_04_27_10_28_00.wav.csv\n",
      "caused error when concatenating starts and stops: llb3_2262_2018_04_28_12_48_28.wav.csv\n",
      "caused error when concatenating starts and stops: llb3_2499_2018_04_28_17_56_45.wav.csv\n",
      "caused error when concatenating starts and stops: llb3_2548_2018_04_29_06_08_41.wav.csv\n",
      "caused error when concatenating starts and stops: llb3_3072_2018_04_30_08_57_33.wav.csv\n",
      "caused error when concatenating starts and stops: llb3_3235_2018_04_30_17_47_04.wav.csv\n",
      "caused error when concatenating starts and stops: llb3_3560_2018_05_01_14_57_40.wav.csv\n"
     ]
    }
   ],
   "source": [
    "needs_removing = defaultdict(list)\n",
    "\n",
    "for bird_id in BIRD_IDS:\n",
    "    files_root = DATASET_ROOT / f\"{bird_id}_data/{bird_id}_songs\"\n",
    "    wav_paths = voc.paths.from_dir(files_root, '.wav')\n",
    "    csv_paths = voc.paths.from_dir(files_root, '.wav.csv')\n",
    "    assert len(wav_paths) == len(csv_paths), \"len(wav_paths) != len(csv_paths)\"\n",
    "    for wav_path, csv_path in zip(wav_paths, csv_paths):\n",
    "        simpleseq = SCRIBE.from_file(csv_path)\n",
    "        try:\n",
    "            voc.metrics.segmentation.ir.concat_starts_and_stops(\n",
    "                simpleseq.onsets_s, simpleseq.offsets_s\n",
    "            )\n",
    "        except:\n",
    "            print(\n",
    "                f\"caused error when concatenating starts and stops: {csv_path.name}\"\n",
    "            )\n",
    "            needs_removing[bird_id].append(\n",
    "                (wav_path, csv_path)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13dfcdfd-1476-4e91-9bcf-9112b0bc96ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number that will be removed from dataset for bird ID llb11: 4 / 2031 = 0.20%\n",
      "moving wav and csv path for: llb11_01876_2018_05_08_11_55_42\n",
      "moving wav and csv path for: llb11_02147_2018_05_08_16_01_55\n",
      "moving wav and csv path for: llb11_02473_2018_05_09_09_57_01\n",
      "moving wav and csv path for: llb11_03556_2018_05_11_10_08_16\n",
      "Number that will be removed from dataset for bird ID llb3: 17 / 2631 = 0.65%\n",
      "moving wav and csv path for: llb3_0357_2018_04_24_17_09_44\n",
      "moving wav and csv path for: llb3_0668_2018_04_25_14_50_17\n",
      "moving wav and csv path for: llb3_0800_2018_04_25_17_49_23\n",
      "moving wav and csv path for: llb3_0804_2018_04_25_17_50_45\n",
      "moving wav and csv path for: llb3_0824_2018_04_25_18_20_08\n",
      "moving wav and csv path for: llb3_1122_2018_04_26_11_49_21\n",
      "moving wav and csv path for: llb3_1124_2018_04_26_11_50_05\n",
      "moving wav and csv path for: llb3_1170_2018_04_26_12_25_11\n",
      "moving wav and csv path for: llb3_1412_2018_04_26_17_51_20\n",
      "moving wav and csv path for: llb3_1559_2018_04_27_08_04_31\n",
      "moving wav and csv path for: llb3_1673_2018_04_27_10_28_00\n",
      "moving wav and csv path for: llb3_2262_2018_04_28_12_48_28\n",
      "moving wav and csv path for: llb3_2499_2018_04_28_17_56_45\n",
      "moving wav and csv path for: llb3_2548_2018_04_29_06_08_41\n",
      "moving wav and csv path for: llb3_3072_2018_04_30_08_57_33\n",
      "moving wav and csv path for: llb3_3235_2018_04_30_17_47_04\n",
      "moving wav and csv path for: llb3_3560_2018_05_01_14_57_40\n"
     ]
    }
   ],
   "source": [
    "for bird_id, needs_removing_list in needs_removing.items():\n",
    "    if len(needs_removing_list) < 1:\n",
    "        print(f\"No issue with onset/offset times for bird ID: {bird_id}\")\n",
    "        continue\n",
    "\n",
    "    files_root = DATASET_ROOT / f\"{bird_id}_data/{bird_id}_songs\"\n",
    "    all_wav_paths = voc.paths.from_dir(files_root, '.wav')\n",
    "    n_that_need_removing = len(needs_removing[bird_id])\n",
    "    print(\n",
    "        f\"Number that will be removed from dataset for bird ID {bird_id}: {n_that_need_removing} / {len(all_wav_paths)} = \"\n",
    "        f\"{n_that_need_removing / len(all_wav_paths) * 100:.2f}%\"\n",
    "    )\n",
    "    onset_offset_times_issues_dir = files_root / \"onset_offset_times_issues\"\n",
    "    if not DRY_RUN:\n",
    "        onset_offset_times_issues_dir.mkdir(exist_ok=True)\n",
    "    for wav_path, csv_path in needs_removing_list:\n",
    "        print(f\"moving wav and csv path for: {wav_path.stem}\")\n",
    "        if not DRY_RUN:\n",
    "            shutil.move(wav_path, onset_offset_times_issues_dir)\n",
    "            shutil.move(csv_path, onset_offset_times_issues_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
